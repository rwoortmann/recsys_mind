{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_sparse import SparseTensor, spmm\n",
    "\n",
    "from metrics import *\n",
    "from transformer import SentenceTransformer\n",
    "from mind_utils import *\n",
    "\n",
    "TRAIN_S = './data/mind/training_small'\n",
    "TRAIN_L = './data/mind/training_large'\n",
    "VAL_S = '/data/mind/validation_small'\n",
    "VAL_L = '/data/mind/validation_large'\n",
    "TEST = '/data/mind/mind/test'\n",
    "\n",
    "log_dir = './runs/tb/'\n",
    "model_dir = './runs/models/'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from mind_utils import *\n",
    "import torch\n",
    "\n",
    "class DataGraph(object):\n",
    "    def __init__(self, set_dir, text_enc, device):\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        news_df = self.get_news(set_dir)\n",
    "        hist_df = self.get_user_history(set_dir)\n",
    "\n",
    "        self.mapping = {}\n",
    "        self.mapping['news'] = self.map_col(news_df.news_id)\n",
    "        self.mapping['users'] = self.map_col(hist_df.user_id)\n",
    "        \n",
    "        self.news_x = self.get_news_x(text_enc, news_df).to(device)\n",
    "        self.edge_index = self.load_edge_index(hist_df.explode('history'), 'history', 'user_id', 'users')\n",
    "       \n",
    "        self.n_nodes = {key: len(self.mapping[key]) for key in self.mapping.keys()}\n",
    "   \n",
    "        \n",
    "    def map_col(self, column):\n",
    "        return {index: i for i, index in enumerate(column.unique())} \n",
    "         \n",
    "         \n",
    "    def load_edge_index(self, df, news_col, atr_col, atr_map):\n",
    "        news_edge = [self.mapping['news'][index] for index in df[news_col]]\n",
    "        atr_edge = [self.mapping[atr_map][index] for index in df[atr_col]]\n",
    " \n",
    "        return torch.tensor([news_edge, atr_edge]).to(self.device)\n",
    "        \n",
    "\n",
    "    def get_news_x(self, text_enc, news_df):\n",
    "        news_text = news_df['title'] + ' ' + news_df['abstract'].fillna('')\n",
    "        news_x =  text_enc.encode(news_text.values)\n",
    "        # remove zero'd columns\n",
    "        news_x = news_x[:, news_x.std(dim=0) != 0.]\n",
    "        # standardize\n",
    "        news_x = (news_x - news_x.mean(dim=0)) / news_x.std(dim=0)\n",
    "        return news_x\n",
    "        \n",
    "      \n",
    "    def get_user_history(self, set_dir):\n",
    "        df = get_behaviors(set_dir)\n",
    "        user_hist = df[['user_id', 'history']].drop_duplicates().dropna(subset=['history'])\n",
    "        user_hist['history'] = user_hist['history'].str.split(' ') \n",
    "        return user_hist\n",
    "\n",
    "\n",
    "    def get_news(self, set_dir):\n",
    "        news_path = os.path.join(set_dir, 'news.tsv')\n",
    "        news = pd.read_table(news_path,\n",
    "                            quoting=csv.QUOTE_NONE,\n",
    "                            header=None,\n",
    "                            names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'url',\n",
    "                                    'title_entities', 'abstract_entities'])\n",
    "        news['title_entities'] = news['title_entities'].apply(lambda row: json.loads(row))\n",
    "        return news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(exp_name, train_loader, model, epochs, batch_size, test=False):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    exp_dir = log_dir + exp_name\n",
    "    if os.path.exists(exp_dir) and os.path.isdir(exp_dir):\n",
    "        shutil.rmtree(exp_dir) \n",
    "    writer = SummaryWriter(log_dir=exp_dir)\n",
    "\n",
    "    \n",
    "    \n",
    "    losses, pos_accs, neg_accs = [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        for b_i, batch in enumerate(train_loader):\n",
    "\n",
    "            \n",
    "            subgraph, news_x, b_users, b_articles, b_n_pos, b_n_neg = batch\n",
    "            subgraph_feats = model(news_x, subgraph)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "            \n",
    "                user, articles, n_pos, n_neg = b_users[i], b_articles[i], b_n_pos[i], b_n_neg[i]\n",
    "    \n",
    "                user_emb = subgraph_feats['users'][user]\n",
    "                art_emb = subgraph_feats['news'][articles]\n",
    "\n",
    "                scores = angular_distance(user_emb, art_emb)\n",
    "\n",
    "                targets = torch.zeros(n_pos+n_neg, device=device)\n",
    "                weights = torch.full(targets.shape, 1/n_neg, device=device)\n",
    "                targets[:n_pos] = 1\n",
    "                weights[:n_pos] = 1/n_pos\n",
    "\n",
    "                loss = F.binary_cross_entropy(scores, targets, (weights/2), reduction='sum')\n",
    "\n",
    "                pos_accs.append((scores[:n_pos].round() == 1).mean().cpu().numpy())\n",
    "                neg_accs.append((scores[n_pos:].round() == 0).mean().cpu().numpy())\n",
    "                losses.append(loss.item())\n",
    "                \n",
    "    \n",
    "                if (i+1) != batch_size:\n",
    "                    loss.backward(retain_graph=True)\n",
    "                \n",
    "                elif (i+1) == batch_size:\n",
    "                    loss.backward(retain_graph=False)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            if b_i == 1000:\n",
    "                writer.add_scalar('pos_acc', np.mean(pos_accs), (epoch+1)*(b_i * batch_size))\n",
    "                writer.add_scalar('neg_acc', np.mean(neg_accs), (epoch+1)*(b_i * batch_size))\n",
    "                writer.add_scalar('loss', np.mean(losses), (epoch+1)*(b_i * batch_size))\n",
    "                losses, pos_accs, neg_accs = [], [], []\n",
    "    \n",
    "                \n",
    "\n",
    "            if b_i == 200 and test:\n",
    "                break\n",
    "            \n",
    "        if not test:\n",
    "            torch.save(model.state_dict(), f'{model_dir+exp_name}_epoch_{epoch}')\n",
    "                \n",
    "                \n",
    "    writer.close()\n",
    "    #torch.save(model.state_dict(), model_dir+exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(exp_name, model, writer, iteration):\n",
    "\n",
    "    exp_dir = log_dir + exp_name + '_eval'\n",
    "    if os.path.exists(exp_dir) and os.path.isdir(exp_dir):\n",
    "        shutil.rmtree(exp_dir) \n",
    "    writer = SummaryWriter(log_dir=exp_dir)      \n",
    "    \n",
    "    if not model:\n",
    "        model = GCN(val_data.features['news'].shape[1], empty_nodes, atr_nodes).to(device)\n",
    "        model.load_state_dict(torch.load(model_dir + exp_name), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = model(val_data, val_data.edge_index)\n",
    "\n",
    "\n",
    "        aucs, mrrs, ndcg5s, ndcg10s, = [], [], [], []\n",
    "        pos_accs, neg_accs = [], []\n",
    "\n",
    "        for i, batch in enumerate(val_sessions):\n",
    "            user, pos, neg = batch\n",
    "            pos, neg = pos.reshape(-1), neg.reshape(-1)\n",
    "            n_pos, n_neg = pos.shape[0], neg.shape[0]\n",
    "\n",
    "            #subgraph = get_subgraph(val_data, user, pos.reshape(-1), neg.reshape(-1))  \n",
    "            #subgraph_feats = model(val_data, subgraph)\n",
    "            #user_emb = subgraph_feats['users'][user]\n",
    "            #art_emb = torch.index_select(subgraph_feats['news'], 0, torch.cat((pos, neg), dim=1).squeeze())\n",
    "\n",
    "            user_emb = feats['users'][user]\n",
    "            art_emb = feats['news'][torch.cat((pos, neg))]\n",
    "\n",
    "            scores = angular_distance(user_emb, art_emb)\n",
    "\n",
    "            targets = torch.zeros(scores.shape, device=device)\n",
    "            targets[:n_pos] = 1\n",
    "\n",
    "            pos_accs.append((torch.round(scores[:n_pos]) == 1).float().mean().cpu().numpy())\n",
    "            neg_accs.append((torch.round(scores[n_pos:]) == 0).float().mean().cpu().numpy())\n",
    "\n",
    "            #writer.add_scalar('pos_acc', pos_acc, i)\n",
    "            #writer.add_scalar('neg_acc', neg_acc, i)\n",
    "\n",
    "\n",
    "            ranks = (torch.argsort(scores, descending=True)+1).cpu().numpy()\n",
    "            y_score = [1./rank for rank in ranks]\n",
    "            y_true = targets.cpu().numpy()\n",
    "\n",
    "            auc = roc_auc_score(y_true,y_score)\n",
    "            mrr = mrr_score(y_true,y_score)\n",
    "            ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "            ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "\n",
    "            aucs.append(auc)\n",
    "            mrrs.append(mrr)\n",
    "            ndcg5s.append(ndcg5)\n",
    "            ndcg10s.append(ndcg10)\n",
    "                   \n",
    "    \n",
    "    writer.add_scalar('auc', np.mean(aucs), iteration)\n",
    "    writer.add_scalar('mrr', np.mean(mrrs), iteration)\n",
    "    writer.add_scalar('ndcg5', np.mean(ndcg5s), iteration)\n",
    "    writer.add_scalar('ndcg10', np.mean(ndcg10s), iteration)\n",
    "    writer.add_scalar('val_pos_acc', np.mean(pos_accs), iteration)\n",
    "    writer.add_scalar('val_neg_acc', np.mean(neg_accs), iteration)\n",
    "    \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LayerNorm, GraphNorm, InstanceNorm\n",
    "from torch_geometric.utils import degree\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "        self.act = nn.Tanh()\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "###\n",
    "# Layers\n",
    "###\n",
    "\n",
    "class FirstConv(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.FFN = MLP(in_channels, hidden_channels, out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):\n",
    "        n_neighbors = degree(edge_index.storage.col(), num_nodes=edge_index.storage._sparse_sizes[1])\n",
    "        agr_feats = edge_index.t() @ subgraph_feats['news']\n",
    "        agr_feats = agr_feats / (n_neighbors[:,None] + 1e-08)\n",
    "        \n",
    "        out = self.FFN(agr_feats)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "class NewsConv(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.FFN = MLP(in_channels, hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):\n",
    "        n_neighbors = degree(edge_index.storage.row(), num_nodes=edge_index.storage._sparse_sizes[0])\n",
    "        agr_feats = edge_index @ subgraph_feats['users']\n",
    "        agr_feats = agr_feats / (n_neighbors[:,None] + 1e-08)\n",
    "\n",
    "        out = torch.cat((subgraph_feats['news'], agr_feats), dim=1)\n",
    "        out = self.FFN(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "class UserConv(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.FFN = MLP(in_channels, hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):\n",
    "        n_neighbors = degree(edge_index.storage.col(), num_nodes=edge_index.storage._sparse_sizes[1])\n",
    "        agr_feats = edge_index.t() @ subgraph_feats['news']\n",
    "        agr_feats = agr_feats / (n_neighbors[:,None] + 1e-08)\n",
    "    \n",
    "        out = torch.cat((subgraph_feats['users'], agr_feats), dim=1)\n",
    "        out = self.FFN(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "## Net    \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, news_dim):\n",
    "        super().__init__()\n",
    "        in_dim = news_dim\n",
    "        hidden_dim = 256\n",
    "        out_dim = in_dim\n",
    "                \n",
    "        self.first_conv = FirstConv(in_dim, hidden_dim, out_dim)\n",
    "        self.news_conv = NewsConv(in_dim + out_dim, hidden_dim*2, out_dim)\n",
    "        self.user_conv = UserConv(out_dim*2, hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, news_x, edge_index):\n",
    "\n",
    "        subgraph_feats = {'news': news_x}\n",
    "        \n",
    "        # prop news feats to empty user nodes\n",
    "        subgraph_feats['users'] = self.first_conv(subgraph_feats, edge_index)\n",
    "\n",
    "        # update news nodes\n",
    "        subgraph_feats['news'] = self.news_conv(subgraph_feats, edge_index)\n",
    "        \n",
    "        # update atr nodes\n",
    "        subgraph_feats['users'] = self.user_conv(subgraph_feats, edge_index)\n",
    "          \n",
    "        return subgraph_feats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.mask import index_to_mask\n",
    "from torch_geometric.utils import dropout_edge\n",
    "\n",
    "class Impressions(Dataset):\n",
    "    def __init__(self, data, set_dir, device=device):\n",
    "        self.device = device\n",
    "        df = get_behaviors(set_dir).dropna(subset=['history'])\n",
    "        \n",
    "        self.user = [data.mapping['users'][user_id] for user_id in df.user_id]\n",
    "        self.pos = [[data.mapping['news'][article] for article in session] for session in df.pos]\n",
    "        self.neg = [[data.mapping['news'][article] for article in session] for session in df.neg]\n",
    "        \n",
    "        self.edge_index = data.edge_index\n",
    "        \n",
    "        self.n_nodes = data.n_nodes\n",
    "        self.news_x = data.news_x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pos)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user = torch.tensor(self.user[idx], dtype=torch.long, device=self.device)\n",
    "        \n",
    "        pos = self.pos[idx]\n",
    "        neg = self.neg[idx]\n",
    "        \n",
    "        n_pos = len(pos)\n",
    "        n_neg = len(neg)\n",
    "        \n",
    "        articles = torch.tensor(pos + neg, dtype=torch.long, device=self.device)\n",
    "\n",
    "        return user, articles, n_pos, n_neg, n_pos+n_neg\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def relabel_nodes(self, subset, edge_index, size, targets):\n",
    "        '''\n",
    "        Relabels the sampled edge_index so that node indices range from [0...n_sampled_nodes] instead of [0...n_all_nodes]\n",
    "        Input:\n",
    "        subset: tuple of (news, atr) nodes to be included\n",
    "        edge_index: edges from sampling\n",
    "        size: amount of nodes in non-sampled graph\n",
    "        '''\n",
    "        \n",
    "        news_subset, user_subset = subset\n",
    "        articles, users = targets     \n",
    "\n",
    "        news_subset = index_to_mask(news_subset, size=size[0])           \n",
    "        user_subset = index_to_mask(user_subset, size=size[1])\n",
    "        \n",
    "        # relabel nodes\n",
    "        node_idx_news = edge_index.new_zeros(news_subset.size(0))\n",
    "        node_idx_user = edge_index.new_zeros(user_subset.size(0))\n",
    "        \n",
    "        node_idx_news[news_subset] = torch.arange(int(news_subset.sum()),\n",
    "                                            device=node_idx_news.device)\n",
    "\n",
    "        node_idx_user[user_subset] = torch.arange(int(user_subset.sum()),\n",
    "                                            device=node_idx_user.device)\n",
    "\n",
    "\n",
    "        articles = node_idx_news[articles]\n",
    "        users = node_idx_user[users]\n",
    "\n",
    "        edge_index = torch.stack([\n",
    "            node_idx_news[edge_index[0]],\n",
    "            node_idx_user[edge_index[1]],\n",
    "        ], dim=0)\n",
    "\n",
    "        return edge_index, articles, users\n",
    "\n",
    "    def dropout_nodes(self, p, edge_index, n_nodes, dim):\n",
    "        prob = torch.rand(n_nodes, device=edge_index.device)\n",
    "        node_mask = prob > p\n",
    "        \n",
    "        edge_mask = node_mask[edge_index[dim]]\n",
    "        edge_index = edge_index[:, edge_mask]\n",
    "        return edge_index\n",
    "\n",
    "\n",
    "\n",
    "    def sampler(self, users, articles):\n",
    "\n",
    "        # Hop 1: article history for target user\n",
    "        sample = self.edge_index[:, torch.isin(self.edge_index[1], users)]\n",
    "        new_index = sample\n",
    "        to_sample = torch.cat((sample[0], articles))\n",
    "\n",
    "        # Hop 2: users connected to article history + target articles\n",
    "        sample = self.edge_index[:, torch.isin(self.edge_index[0], to_sample)]\n",
    "        sample = self.dropout_nodes(0.7, sample, self.n_nodes['users'], 1)\n",
    "        new_index = torch.cat((new_index, sample), dim=1)\n",
    "        to_sample = sample[1]\n",
    "\n",
    "        # Hop 3: grab articles from these users\n",
    "        sample = self.edge_index[:, torch.isin(self.edge_index[1], to_sample)]\n",
    "        ssample = self.dropout_nodes(0.5, sample, self.n_nodes['news'], 0)\n",
    "        new_index = torch.cat((new_index, sample), dim=1)\n",
    "\n",
    "        # relabel\n",
    "        news_nodes = torch.cat((new_index[0], articles)).unique()\n",
    "        user_nodes = new_index[1].unique()\n",
    "        \n",
    "        index, articles, users = self.relabel_nodes((news_nodes, user_nodes), \n",
    "                                                        new_index, \n",
    "                                                        (self.n_nodes['news'], self.n_nodes['users']),\n",
    "                                                        (articles, users))\n",
    "\n",
    "        edge_index = SparseTensor.from_edge_index(index, sparse_sizes=(news_nodes.shape[0], user_nodes.shape[0]))\n",
    "        \n",
    "        news_x = self.news_x[news_nodes]\n",
    "\n",
    "        return edge_index, news_x, articles, users\n",
    "    \n",
    "    \n",
    "    \n",
    "    def collate(self, batch):\n",
    "\n",
    "        users, articles, n_pos, n_neg, n_all = list(zip(*batch))\n",
    "\n",
    "        subgraph, news_x, articles, users = self.sampler(torch.stack(users), torch.cat(articles))\n",
    "\n",
    "        articles = torch.split(articles, n_all)\n",
    "\n",
    "        return subgraph, news_x, users, articles, n_pos, n_neg\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LayerNorm, InstanceNorm\n",
    "from torch_geometric.utils import degree\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class NewsEnc(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.act = nn.PReLU()\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(out_channels, out_channels)\n",
    "        self.norm = InstanceNorm(out_channels)\n",
    "        self.act = nn.PReLU()\n",
    "    \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.norm.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x  \n",
    "\n",
    "\n",
    "\n",
    "class PostLayer(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(out_channels, out_channels)\n",
    "        self.lin2 = nn.Linear(out_channels, out_channels)\n",
    "        self.act = nn.Tanh()\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# Layers\n",
    "###\n",
    "\n",
    "class FirstConv(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = GNNLayer(out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):\n",
    "        n_neighbors = degree(edge_index.storage.col(), num_nodes=edge_index.storage._sparse_sizes[1])\n",
    "        \n",
    "        x = subgraph_feats['news']\n",
    "        x = self.layer(x)\n",
    "        \n",
    "        agr_feats = edge_index.t() @ x\n",
    "        out = agr_feats / n_neighbors[:,None]\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "class NewsConv(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = GNNLayer(out_channels)\n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):     \n",
    "        n_neighbors = degree(edge_index.storage.row(), num_nodes=edge_index.storage._sparse_sizes[0])\n",
    "\n",
    "        x = self.layer(subgraph_feats['users'])\n",
    "\n",
    "        agr_feats = edge_index @ x\n",
    "        agr_feats = agr_feats / (n_neighbors[:,None] + 1e-08)\n",
    "        \n",
    "        out = subgraph_feats['news'] + agr_feats\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "class UserConv(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = GNNLayer(out_channels)\n",
    "        \n",
    "    def forward(self, subgraph_feats, edge_index):\n",
    "        n_neighbors = degree(edge_index.storage.col(), num_nodes=edge_index.storage._sparse_sizes[1])\n",
    "\n",
    "        x = self.layer(subgraph_feats['news'])\n",
    "\n",
    "        agr_feats = edge_index.t() @ x\n",
    "        agr_feats = agr_feats / (n_neighbors[:,None] + 1e-08)\n",
    "    \n",
    "        out = subgraph_feats['users'] + agr_feats\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "## Net    \n",
    "class GCN2(nn.Module):\n",
    "    def __init__(self, news_dim):\n",
    "        super().__init__()\n",
    "        out_dim = 128\n",
    "                \n",
    "        self.news_enc = MLP(news_dim, 256, out_dim)\n",
    "        \n",
    "        self.first_conv = FirstConv(out_dim)\n",
    "        self.news_conv = NewsConv(out_dim)\n",
    "        self.user_conv = UserConv(out_dim)\n",
    "        \n",
    "        self.news_post = PostLayer(out_dim)\n",
    "        self.user_post = PostLayer(out_dim)\n",
    "        \n",
    "    def forward(self, news_x, edge_index):\n",
    "\n",
    "        subgraph_feats = {'news': self.news_enc(news_x)}\n",
    "        \n",
    "        # prop news feats to empty user nodes\n",
    "        subgraph_feats['users'] = self.first_conv(subgraph_feats, edge_index)\n",
    "\n",
    "        # update news nodes\n",
    "        subgraph_feats['news'] = self.news_conv(subgraph_feats, edge_index)\n",
    "        \n",
    "        # update atr nodes\n",
    "        subgraph_feats['users'] = self.user_conv(subgraph_feats, edge_index)\n",
    "\n",
    "        # post\n",
    "        subgraph_feats['news'] = self.news_post(subgraph_feats['news'])\n",
    "        subgraph_feats['users'] = self.user_post(subgraph_feats['users'])\n",
    "\n",
    "        return subgraph_feats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "TRAIN_DIR = TRAIN_L\n",
    "VAL_DIR = VAL_L\n",
    "\n",
    "\n",
    "\n",
    "#st_model = 'all-MiniLM-L6-v2'\n",
    "st_model = 'all-mpnet-base-v2'\n",
    "encoder = SentenceTransformer(st_model, 'cuda')\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "#train_data = DataGraph(TRAIN_DIR, encoder, device)\n",
    "#train_impressions = Impressions(train_data, TRAIN_DIR)\n",
    "#train_loader = DataLoader(train_impressions,  batch_size, shuffle=True, collate_fn=train_impressions.collate) #set shuffle true\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "model = GCN2(train_data.news_x.shape[1]).to(device)\n",
    "print('training')\n",
    "train('L_biglm', train_loader, model, epochs, batch_size, test=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    if i == 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys-mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55587e0a113dde538d0f7e94e64feeec557c7d17d9d5b3f867e14656d8e6f5b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
